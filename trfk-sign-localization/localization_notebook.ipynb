{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%git clone https://github.com/ultralytics/yolov5.git"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1973,"status":"ok","timestamp":1656872654840,"user":{"displayName":"Impractical9","userId":"05922030616930076878"},"user_tz":-120},"id":"btIRG13vIPxt","outputId":"8dbfebf6-8183-462b-9c5c-00e6f9ae1228"},"outputs":[],"source":["%pip install -r yolov5/requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3074,"status":"ok","timestamp":1656872657910,"user":{"displayName":"Impractical9","userId":"05922030616930076878"},"user_tz":-120},"id":"P3VfXR2ZIRT3"},"outputs":[],"source":["import torch\n","from IPython.display import Image  # for displaying images\n","import os \n","import random\n","import shutil\n","from sklearn.model_selection import train_test_split\n","import xml.etree.ElementTree as ET\n","from xml.dom import minidom\n","from tqdm import tqdm\n","from PIL import Image, ImageDraw\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","random.seed(108)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1656872657911,"user":{"displayName":"Impractical9","userId":"05922030616930076878"},"user_tz":-120},"id":"MzvphGEwIZ6o","outputId":"24cc625d-926c-4884-d807-3f41da19e5f7"},"outputs":[],"source":["%mkdir dataset\n","%cd dataset\n","%wget -O RoadSignDetectionDataset.zip https://arcraftimages.s3-accelerate.amazonaws.com/Datasets/CarsAndTrafficSigns/CarsAndTrafficSignsPascalVOC.zip?region=us-east-2\n","%unzip RoadSignDetectionDataset.zip\n","%rm -r __MACOSX RoadSignDetectionDataset.zip\n","%mv annotations labels"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def extract_info_from_xml(xml_file):\n","    root = ET.parse(xml_file).getroot()\n","    # Initialise the info dict \n","    info_dict = {}\n","    info_dict['bboxes'] = []\n","    # Parse the XML Tree\n","    for elem in root:\n","        # Get the file name \n","        if elem.tag == \"filename\":\n","            info_dict['filename'] = elem.text\n","        # Get the image size\n","        elif elem.tag == \"size\":\n","            image_size = []\n","            for subelem in elem:\n","                image_size.append(int(subelem.text))\n","            info_dict['image_size'] = tuple(image_size)\n","        # Get details of the bounding box \n","        elif elem.tag == \"object\":\n","            bbox = {}\n","            for subelem in elem:\n","                if subelem.tag == \"name\":\n","                    bbox[\"class\"] = subelem.text\n","                elif subelem.tag == \"bndbox\":\n","                    for subsubelem in subelem:\n","                        bbox[subsubelem.tag] = int(subsubelem.text)            \n","            info_dict['bboxes'].append(bbox)\n","    return info_dict\n","# Dictionary that maps class names to IDs\n","class_name_to_id_mapping = {\"traffic sign\": 0,\n","                            \"traffic light\": 1,\n","                            \"person\": 2,\n","                            \"car\": 3,\n","                            \"truck\": 4,\n","                            \"bike\": 5,\n","                            \"rider\": 6,\n","                            \"bus\": 7,\n","                            \"motor\": 8,\n","                            \"train\": 9}\n","# Convert the info dict to the required yolo format and write it to disk\n","def convert_to_yolov5(info_dict):\n","    print_buffer = []\n","    MIN = 15 # Minimum width and height of the bounding box\n","    # For each bounding box\n","    for b in info_dict[\"bboxes\"]:\n","        try:\n","            class_id = class_name_to_id_mapping[b[\"class\"]]\n","        except KeyError:\n","            print(\"Invalid Class. Must be one from \", class_name_to_id_mapping.keys())\n","            # Transform the bbox co-ordinates as per the format required by YOLO v5\n","        b_center_x = (b[\"xmin\"] + b[\"xmax\"]) / 2 \n","        b_center_y = (b[\"ymin\"] + b[\"ymax\"]) / 2\n","        b_width    = (b[\"xmax\"] - b[\"xmin\"])\n","        b_height   = (b[\"ymax\"] - b[\"ymin\"])\n","        if b_width > MIN and b_height > MIN and class_id in [0, 1]:\n","            # Normalise the co-ordinates by the dimensions of the image\n","            image_w, image_h, image_c = info_dict[\"image_size\"]  \n","            b_center_x /= image_w \n","            b_center_y /= image_h \n","            b_width    /= image_w \n","            b_height   /= image_h \n","            #Write the bbox details to the file \n","            print_buffer.append(\"{} {:.5f} {:.5f} {:.5f} {:.5f}\".format(class_id, b_center_x, b_center_y, b_width, b_height))\n","            print(\"{} {:.5f} {:.5f} {:.5f} {:.5f}\".format(class_id, b_center_x, b_center_y, b_width, b_height))    \n","    # Name of the file which we have to save \n","    save_file_name = os.path.join(\"labels\", info_dict[\"filename\"].replace(\"png\", \"txt\"))\n","    # Save the label to disk\n","    print(\"\\n\".join(print_buffer), file= open(save_file_name, \"w\"))\n","# Get the labels\n","labels = [os.path.join('labels', x) for x in os.listdir('labels') if x[-3:] == \"xml\"]\n","labels.sort()\n","# Convert and save the labels\n","for ann in tqdm(labels):\n","    info_dict = extract_info_from_xml(ann)\n","    convert_to_yolov5(info_dict)\n","labels = [os.path.join('labels', x) for x in os.listdir('labels') if x[-3:] == \"txt\"]\n","class_id_to_name_mapping = dict(zip(class_name_to_id_mapping.values(), class_name_to_id_mapping.keys()))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%mkdir images/train images/val images/test labels/train labels/val labels/test"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1656872739567,"user":{"displayName":"Impractical9","userId":"05922030616930076878"},"user_tz":-120},"id":"rwGWfwt8K-0-"},"outputs":[],"source":["# Read images and labels\n","images = [os.path.join('images', x) for x in os.listdir('images') if x[-3:] == \"png\"].sort()\n","labels = [os.path.join('labels', x) for x in os.listdir('labels') if x[-3:] == \"txt\"].sort()\n","# Split the dataset into train-valid-test splits \n","train_images, val_images, train_labels, val_labels = train_test_split(images, labels, test_size = 0.2, random_state = 1)\n","val_images, test_images, val_labels, test_labels = train_test_split(val_images, val_labels, test_size = 0.5, random_state = 1)\n","#Utility function to move images \n","def move_files_to_folder(list_of_files, destination_folder):\n","    for f in list_of_files:\n","        try:\n","            shutil.move(f, destination_folder)\n","        except:\n","            print(f)\n","            assert False\n","    print(destination_folder, \"done\")\n","# Move the splits into their folders\n","move_files_to_folder(train_images, 'images/train')\n","move_files_to_folder(val_images, 'images/val/')\n","move_files_to_folder(test_images, 'images/test/')\n","move_files_to_folder(train_labels, 'labels/train/')\n","move_files_to_folder(val_labels, 'labels/val/')\n","move_files_to_folder(test_labels, 'labels/test/')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4078,"status":"ok","timestamp":1656872743640,"user":{"displayName":"Impractical9","userId":"05922030616930076878"},"user_tz":-120},"id":"op9vztA1Mm_J","outputId":"63f9d6e0-c55c-46a3-ebbc-ea4a55b53a45"},"outputs":[],"source":["# Get the labels\n","labels = [os.path.join('labels', x) for x in os.listdir('labels') if x[-3:] == \"xml\"]\n","labels.sort()\n","\n","# Convert and save the labels\n","for ann in tqdm(labels):\n","    info_dict = extract_info_from_xml(ann)\n","    convert_to_yolov5(info_dict)\n","labels = [os.path.join('labels', x) for x in os.listdir('labels') if x[-3:] == \"txt\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":240},"executionInfo":{"elapsed":1575,"status":"ok","timestamp":1656872745210,"user":{"displayName":"Impractical9","userId":"05922030616930076878"},"user_tz":-120},"id":"sS1ru-22MsUz","outputId":"87db6607-3254-480c-a827-bc592e92e6cf"},"outputs":[],"source":["random.seed(0)\n","\n","class_id_to_name_mapping = dict(zip(class_name_to_id_mapping.values(), class_name_to_id_mapping.keys()))\n","\n","def plot_bounding_box(image, annotation_list):\n","    labels = np.array(annotation_list)\n","    w, h = image.size\n","    \n","    plotted_image = ImageDraw.Draw(image)\n","\n","    transformed_labels = np.copy(labels)\n","    transformed_labels[:,[1,3]] = labels[:,[1,3]] * w\n","    transformed_labels[:,[2,4]] = labels[:,[2,4]] * h \n","    \n","    transformed_labels[:,1] = transformed_labels[:,1] - (transformed_labels[:,3] / 2)\n","    transformed_labels[:,2] = transformed_labels[:,2] - (transformed_labels[:,4] / 2)\n","    transformed_labels[:,3] = transformed_labels[:,1] + transformed_labels[:,3]\n","    transformed_labels[:,4] = transformed_labels[:,2] + transformed_labels[:,4]\n","    \n","    for ann in transformed_labels:\n","        obj_cls, x0, y0, x1, y1 = ann\n","        plotted_image.rectangle(((x0,y0), (x1,y1)))\n","        \n","        plotted_image.text((x0, y0 - 10), class_id_to_name_mapping[(int(obj_cls))])\n","    \n","    plt.imshow(np.array(image))\n","    plt.show()\n","\n","# Get any random annotation file \n","annotation_file = random.choice(labels)\n","with open(annotation_file, \"r\") as file:\n","    annotation_list = file.read().split(\"\\n\")[:-1]\n","    annotation_list = [x.split(\" \") for x in annotation_list]\n","    annotation_list = [[float(y) for y in x ] for x in annotation_list]\n","\n","#Get the corresponding image file\n","image_file = annotation_file.replace(\"labels\", \"images\").replace(\"txt\", \"png\")\n","assert os.path.exists(image_file)\n","\n","#Load the image\n","image = Image.open(image_file)\n","\n","#Plot the Bounding Box\n","plot_bounding_box(image, annotation_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1656872745574,"user":{"displayName":"Impractical9","userId":"05922030616930076878"},"user_tz":-120},"id":"mSl6g1zCNMl6","outputId":"d222987b-96f8-46be-980d-63c760f658ec"},"outputs":[],"source":["%cd ..\n","%cp hyp.traffic.yaml yolov5/data/hyps/hyp.traffic.yaml\n","%cp traffic.yaml yolov5/data/traffic.yaml\n","%cd yolov5"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15611383,"status":"ok","timestamp":1656888988933,"user":{"displayName":"Impractical9","userId":"05922030616930076878"},"user_tz":-120},"id":"KV1Nk9BdNR-8","outputId":"cf5ca1dc-e1f7-4628-8fca-43832c138b78"},"outputs":[],"source":["%python3 train.py --img 640 --cfg yolov5s.yaml --data traffic.yaml --weights yolov5s.pt --hyp hyp.traffic.yaml --batch-size -1 --epochs 300 --name traffic --patience 50 --save-period 10 --cache"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":52027,"status":"ok","timestamp":1656889119238,"user":{"displayName":"Impractical9","userId":"05922030616930076878"},"user_tz":-120},"id":"tbrlBP5dYOPZ","outputId":"7edd7e1c-40c7-415b-b174-1a805f9658b1"},"outputs":[],"source":["%python3 detect.py --source ../datasets/traffic/images/test/ --weights runs/train/traffic/weights/best.pt --conf 0.25 --name traffic"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":257},"executionInfo":{"elapsed":990,"status":"ok","timestamp":1656889131799,"user":{"displayName":"Impractical9","userId":"05922030616930076878"},"user_tz":-120},"id":"-fUdHKtAYO68","outputId":"f4c10459-0c1c-47ed-bb86-1b3245be6ce9"},"outputs":[],"source":["detections_dir = \"runs/detect/traffic/\"\n","detection_images = [os.path.join(detections_dir, x) for x in os.listdir(detections_dir)]\n","\n","random_detection_image = Image.open(random.choice(detection_images))\n","plt.imshow(np.array(random_detection_image))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34974,"status":"ok","timestamp":1656889178583,"user":{"displayName":"Impractical9","userId":"05922030616930076878"},"user_tz":-120},"id":"4l9liU44YTiK","outputId":"67371a9f-1967-4623-9546-a44afa5e1057"},"outputs":[],"source":["%python3 val.py --weights runs/train/traffic/weights/best.pt --data traffic.yaml --task test --name traffic"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10046,"status":"ok","timestamp":1656889246642,"user":{"displayName":"Impractical9","userId":"05922030616930076878"},"user_tz":-120},"id":"7KtK-EvQYVcU","outputId":"3a5745c2-7fbc-4bac-c2cf-fc44f78c41f0"},"outputs":[],"source":["%python export.py --weights runs/train/yolo_road_det3/weights/best.pt --include tflite"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyP3KJB1U/JYan08FOs9XKNX","mount_file_id":"1er_LvPs7WHoahRk4NpP7EMYzJjpEvB1F","name":"Untitled0.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.10.7 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.7"},"vscode":{"interpreter":{"hash":"26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"}}},"nbformat":4,"nbformat_minor":0}
